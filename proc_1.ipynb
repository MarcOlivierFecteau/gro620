{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kh7ikCw1dWx5"
   },
   "source": [
    "# GRO620 - Activité procédurale 1\n",
    "\n",
    "Dans cette activité, nous allons principalement travailler sur les éléments nécessaires pour capter une image numériquement, les transformations entre repères 2D et 3D, et l'encodage numérique de la couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45339,
     "status": "ok",
     "timestamp": 1622381462155,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "pC6BnG_3dWyA",
    "outputId": "4486fcd9-17b2-4018-e963-c0b64774adcc"
   },
   "outputs": [],
   "source": [
    "# Préambule\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Si vous utilisez Google Colab, vous devez d'abord monter votre Google Drive\n",
    "## où se trouve vos données. \n",
    "## Commentez les trois lignes suivantes en ajustant le chemin vers votre propre\n",
    "## dossier :\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd /content/gdrive/MyDrive/gro620-e21\n",
    "\n",
    "## Pour retrouver le chemin depuis Jupyter, vous pouvez utiliser ceci :\n",
    "# !ls /content/gdrive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1xSdXoMdWyB"
   },
   "source": [
    "## Acquisition et caractéristiques de la lumière\n",
    "\n",
    "### Q1.1\n",
    "\n",
    "À partir de la figure 2.23 du livre de référence, décrivez en une phrase le rôle de chacune des étapes de la chaîne d'acquisition d'images numériques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPRDNqrrdWyB"
   },
   "source": [
    "Réponse:\n",
    "\n",
    "1) Capture de l'image brute;\n",
    "2) Conversion des données analogues en données digitales;\n",
    "3) Traitement de l'image;\n",
    "4) Encodage et écriture de l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdxhihn2dWyB"
   },
   "source": [
    "### Q1.2\n",
    "\n",
    "Quelle est la différence entre paramètres intrinsèques et extrinsèques du caméra ? Décrivez chaque type en une phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiFuS6rPdWyC"
   },
   "source": [
    "Les paramètres intrinsèques sont les paramètres propres à la caméra, tels que:\n",
    "\n",
    "- Distance focale;\n",
    "- Taille du capteur;\n",
    "- *Shutter speed*.\n",
    "\n",
    "Les paramètres extrinsèques de la caméra ne sont pas propres à une caméra, et définient son environnement, tels que:\n",
    "\n",
    "- Repère(s), et matrice(s) de transformation;\n",
    "- Pose de la caméra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FWZECptdWyC"
   },
   "source": [
    "### Q1.3\n",
    "\n",
    "Soit la configuration intrinsèque d'une caméra représentée par la matrice $K$ :\n",
    "\n",
    "$$\n",
    "K = \\begin{bmatrix} \n",
    " 620 &   0 & 1024 \\\\ \n",
    "   0 & 620 &  512 \\\\ \n",
    "   0 &   0 &    1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Le capteur de cette caméra a une taille de 30 mm x 15 mm.\n",
    "\n",
    "Pouvez-vous estimer la distance focale en mm de la lentille de cette caméra à partir de la matrice $K$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mcfUfXCCdWyC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance focale (mm): 9.082\n"
     ]
    }
   ],
   "source": [
    "# Réponse ici.\n",
    "K = np.array(\n",
    "    [[620.0, 0.0, 1024.0], [0.0, 620.0, 512.0], [0.0, 0.0, 1.0]], dtype=np.float64\n",
    ")\n",
    "width_mm, height_mm = (30, 15)\n",
    "width_px, height_px = (K[0, 2] * 2, K[1, 2] * 2)\n",
    "f_px = K[0, 0]\n",
    "f = f_px * width_mm / width_px  # mm\n",
    "\n",
    "print(f\"Distance focale (mm): {f:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quJcFsPbdWyD"
   },
   "source": [
    "### Q1.4\n",
    "\n",
    "Dans le cadre de cet APP, nous considérons les caméras comme étant idéales, c'est-à-dire qu'on peut obtenir leurs caractéristiques intrinsèques et extrinsèques à partir de quelques paramètres seulement.\n",
    "\n",
    "**a)** Qu'est-ce qui rend les vraies caméras non-idéales ? Nommez des facteurs autant pour les caractéristiques intrinsèques que extrinsèques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erl2fPTidWyD"
   },
   "source": [
    "Réponse:\n",
    "\n",
    "Caractéristiques intrinsèques:\n",
    "\n",
    "- Distortion optique (barillet, coussinet);\n",
    "- Aberrations chromatiques;\n",
    "- Bruit du capteur;\n",
    "- Non-uniformité de la sensibilité des pixels;\n",
    "- Vignetage (*vignetting*);\n",
    "- Erreurs de calibration (*e.g.* distance focale, centre optique).\n",
    "\n",
    "Caractéristiques extrinsèques:\n",
    "\n",
    "- Erreurs dans la pose (position, orientation);\n",
    "- Vibrations, ou mouvements involontaires;\n",
    "- Mauvaise estimation des repères;\n",
    "- Dynamicité de l'environnement (*e.g.* température, lumière);\n",
    "- Flexion, ou déplacement du support de la caméra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sfg46RtdWyD"
   },
   "source": [
    "**b)** Que doit on faire pour obtenir les caractéristiques d'une caméra non-idéale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bezo06eCdWyE"
   },
   "source": [
    "Réponse:\n",
    "\n",
    "Effectuer une calibration expérimentale:\n",
    "\n",
    "- Capturer des images d'un motif connu (*e.g.* damier), puis d'utiliser les algorithmes de calibration pour estimer les paramètres intrinsèques et extrinsèques;\n",
    "- Mesurer les effets de l'environnement, et corriger les erreurs par des modèles ou des ajustements logiciels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhFn190TftCu"
   },
   "source": [
    "### Q1.5\n",
    "\n",
    "Dans cette image synthétique : \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/c/cd/Specular_highlight.jpg)\n",
    "\n",
    "(source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Specular_highlight.jpg))\n",
    "\n",
    "**a)** Quelle(s) partie(s) correspondent à l'illumination diffuse et les reflets spéculaires ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yFIYACqdXa3"
   },
   "source": [
    "Réponse:\n",
    "\n",
    "Les reflets spéculaires correspondent aux points brillants sur les deux boules, et l'illumination diffuse correspond ~~aux parties ombragées de façon *smooth*.~~\n",
    "\n",
    "Solutionnaire: l'illumination diffuse correspond aux couleurs \"retransmises\" par les boules (*i.e.* les couleurs qui n'ont pas été absorbées)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXkcFjFKdXa4"
   },
   "source": [
    "**b)** Quelle information est nécessaire pour déterminer les caractéristiques et emplacements exacts des sources de lumières dans cette image ? Vous pouvez répondre en utilisant des éléments de la *Bidirectional Reflectance Distribution Function* (BRDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGntKizNdXa5",
    "tags": []
   },
   "source": [
    "Réponse:\n",
    "\n",
    "Les éléments nécessaires sont les angles relatifs à la surface des directions incidentes et réfléchies des sources de lumières, et la longueur d'onde de la lumière.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhFn190TftCu"
   },
   "source": [
    "### Q1.6\n",
    "\n",
    "**a)** Pourquoi deux appareils de capture peuvent produire des valeurs RGB différentes d'une même couleur ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4LmStT2f6C1"
   },
   "source": [
    "Réponse:\n",
    "\n",
    "Des facteurs peuvent influencer la représentation digitale de l'information capturée:\n",
    "\n",
    "- Technologie des capteurs;\n",
    "- Disposition des filtres Bayer;\n",
    "- Paramètres d'équilibrage de la couleur (*white balance*);\n",
    "- Algorithmes de traitement d'image;\n",
    "- Portée dynamique, et exposition;\n",
    "- Caractéristiques des lentilles;\n",
    "- Calibration et/ou profiles de couleur;\n",
    "- Conditions de l'éclairage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obSsXTc8f5XM"
   },
   "source": [
    "**b)** Que peut-on faire pour comparer numériquement des couleurs provenant de deux capteurs différents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ629ialf4VV"
   },
   "source": [
    "Réponse:\n",
    "\n",
    "Une démarche de traitement d'image (*i.e.* un *pipeline*):\n",
    "\n",
    "1. Conversion vers un espace de couleurs commun;\n",
    "2. Algorithme pour quantifier la différence de couleur (*e.g.* distance euclidenne, CIE76, CIE94, CIEDE2000);\n",
    "3. Normalisation de la portée des valeurs digitales;\n",
    "4. Analyse statistique pour obtenir la moyenne, la médiane, et l'écart-type des différentes couleurs;\n",
    "5. Visualisation des couleurs dans un espace de couleurs (*e.g.* graphique 3D RGB, graphique 2D CIE);\n",
    "6. (±) Définir un seuil de différence de couleurs raisonnable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKQOpwTVdWyE"
   },
   "source": [
    "## Repères et coordonnées\n",
    "\n",
    "### Q2.1\n",
    "\n",
    "Supposons ces 2 repères :\n",
    "\n",
    "![](images_doc/proc1-q2_1-frames.png)\n",
    "\n",
    "**a)** Trouvez la matrice homogène permettant de transformer un point du repère $\\{1\\}$ au repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jULxdVBsdWyE",
    "outputId": "630316fc-4340-46fa-aa1f-54f653075553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_T_1:\n",
      " [[  0.   1.   0. 240.]\n",
      " [  1.   0.   0.  80.]\n",
      " [  0.   0.  -1. 120.]\n",
      " [  0.   0.   0.   1.]]\n"
     ]
    }
   ],
   "source": [
    "_1_T_0 = np.array([\n",
    "    [0, 1, 0, 240],\n",
    "    [1, 0, 0, 80],\n",
    "    [0, 0, -1, 120],\n",
    "    [0, 0, 0, 1]\n",
    "], dtype=np.float64\n",
    ")\n",
    "print(\"0_T_1:\\n\", _1_T_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJIOwDUPdWyF"
   },
   "source": [
    "**b)** Trouvez maintenant la transformation inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LH35FSWqdWyG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_T_0:\n",
      " [[   0.    1.    0.  -80.]\n",
      " [   1.    0.    0. -240.]\n",
      " [   0.    0.   -1.  120.]\n",
      " [   0.    0.    0.    1.]]\n"
     ]
    }
   ],
   "source": [
    "_1_T_0 = np.array([\n",
    "    [0, 1, 0, -80],\n",
    "    [1, 0, 0, -240],\n",
    "    [0, 0, -1, 120],\n",
    "    [0, 0, 0, 1],\n",
    "], dtype=np.float64\n",
    ")\n",
    "print(\"1_T_0:\\n\", _1_T_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2ximr9WdWyG"
   },
   "source": [
    "**c)** Soit le point $p_0 = [80, 50, 10]^T$, en mm, un point dans le repère $\\{0\\}$. Trouvez $p_1$, ses coordonnées dans le repère $\\{1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nj0k5hkLdWyG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_1:\n",
      " [ -30. -160.  110.    1.]\n"
     ]
    }
   ],
   "source": [
    "p_0 = np.array([80, 50, 10, 1], dtype=np.float64)\n",
    "# p_1 = _1_T_0[:3, :3] @ p_0 + _1_T_0[:3, 3]  # inhomogeneous coordinates\n",
    "p_1 = _1_T_0 @ p_0  # homogeneous coordinates\n",
    "print(\"p_1:\\n\", p_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPkWLvBydWyH"
   },
   "source": [
    "### Q2.2\n",
    "\n",
    "Supposons maintenant que le repère $\\{1\\}$ représente une caméra avec les caractéristiques intrinsèques $K$ de la question Q1.3.\n",
    "\n",
    "**a)** Trouvez la matrice de projection P complète permettant de projeter un point $p$ décrit dans le repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XhSj3FRdWyH",
    "outputId": "ab32f10e-8b2c-4cea-ed94-5ec725bbe94c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:\n",
      " [[6.200e+02 0.000e+00 1.024e+03]\n",
      " [0.000e+00 6.200e+02 5.120e+02]\n",
      " [0.000e+00 0.000e+00 1.000e+00]]\n",
      "0_P_1:\n",
      "[[ 0.000e+00  6.200e+02 -1.024e+03  7.328e+04]\n",
      " [ 6.200e+02  0.000e+00 -5.120e+02 -8.736e+04]\n",
      " [ 0.000e+00  0.000e+00 -1.000e+00  1.200e+02]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"K:\\n\", K)\n",
    "_1_P_0 = K @ _1_T_0[:3, :]\n",
    "\n",
    "_1_P_0_tilde = np.array(\n",
    "    [\n",
    "        [_1_P_0[0, 0], _1_P_0[0, 1], _1_P_0[0, 2], _1_P_0[0, 3]],\n",
    "        [_1_P_0[1, 0], _1_P_0[1, 1], _1_P_0[1, 2], _1_P_0[1, 3]],\n",
    "        [_1_P_0[2, 0], _1_P_0[2, 1], _1_P_0[2, 2], _1_P_0[2, 3]],\n",
    "        [0, 0, 0, 1],\n",
    "    ],\n",
    "    dtype=np.float64,\n",
    ")\n",
    "\n",
    "print(f\"1_P_0_tilde:\\n{_1_P_0_tilde}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UEWupgIdWyI"
   },
   "source": [
    "**b)** Soit le point $p_0 = [250, 10, 0]$, en mm. Trouvez le point $x_s$, les coordonnées du point $p_0$ perçu par la caméra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WryXyIycdWyI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_s:\n",
      " [6.62333333e+02 5.63666667e+02 1.00000000e+00 8.33333333e-03]\n"
     ]
    }
   ],
   "source": [
    "p_0 = np.array([250, 10, 0, 1], np.float64)\n",
    "\n",
    "X_s_prime = _1_P_0_tilde @ p_0\n",
    "X_s = X_s_prime / X_s_prime[2]\n",
    "\n",
    "print(\"X_s:\\n\", X_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpa--SomdWyY"
   },
   "source": [
    "## Reprojection 2D à 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVHRnJsIdWyY"
   },
   "source": [
    "### Q3.1\n",
    "\n",
    "Supposons que le plan XY du repère $\\{0\\}$ est un convoyeur. Quelle serait sa largeur maximale (mesurée sur l'axe Y) si on souhaite que la caméra la capte au complet dans son image ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2WqHjEONdWyZ"
   },
   "outputs": [],
   "source": [
    "p_max = np.array([0, 1024, 1, 1 / 120], dtype=np.float64)\n",
    "\n",
    "# (W_px/2) / Z_c = W_mm / f_px ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jk6xchjCdWyZ"
   },
   "source": [
    "### Q3.2\n",
    "\n",
    "Soit le point $x_s = [120, 200]$, en pixels, un point dans l'image perçu par la caméra décrite plus haut. On suppose que le point perçu se trouve sur le plan XY du repère $\\{0\\}$. Trouvez les coordonnées du point $p_0$ qui correspond à ce même point dans le repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GYiNDm-BdWya"
   },
   "outputs": [],
   "source": [
    "x_s = np.array([120,200])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "proc_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
