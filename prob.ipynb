{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgQOnFaMafaj"
   },
   "source": [
    "# GRO620 - Problématique\n",
    "\n",
    "Voici le fichier de départ de la problématique. Si tout a été installé correctement, vous devriez voir apparaître la première image (DSCF8010.jpeg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tabulate  # Additionnal package to \"pretty print\"\n",
    "\n",
    "print(\"OpenCV version\", cv.__version__)\n",
    "print(\"NumPy version\", np.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "\n",
    "image_filenames = os.listdir(\"photos_prob/\")\n",
    "image_filenames.sort()\n",
    "assert image_filenames is not None\n",
    "print(f\"{len(image_filenames)} images à traiter:\")\n",
    "\n",
    "images: list[cv.typing.MatLike] = []\n",
    "\n",
    "for filename in image_filenames:\n",
    "    path = os.path.join(\"photos_prob/\", filename)\n",
    "    img = cv.imread(path)\n",
    "    assert img is not None\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "\n",
    "plt.figure(0)\n",
    "for index, image in enumerate(images):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Image {index + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.suptitle(\"Histogrammes\")\n",
    "channels = (\"r\", \"g\", \"b\")\n",
    "for index, image in enumerate(images):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    for i, col in enumerate(channels):\n",
    "        hist = cv.calcHist([image], [i], None, [256], [0, 256])\n",
    "        plt.plot(hist, color=col)\n",
    "        plt.xlim([0, 256])\n",
    "        plt.title(f\"Image {index + 1}\")\n",
    "plt.tight_layout(\n",
    "    rect=(0.0, 0.0, 1.0, 0.96)\n",
    ")  # Add vertical padding to avoid overlapping of elements\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe certains motifs récurrents sur les histogrammes:\n",
    "\n",
    "- Les courbes des canaux de couleurs possèdent une allure similaires (entre les canaux d'une image, et les canaux respectifs de toutes les images), et leur \"pic\" se situe entre `[110, 150]`;\n",
    "- Une légère \"bosse\" apparaît entre `[210, 240]`.\n",
    "\n",
    "Considérant que les vis n'occupent qu'une faible partie des images, on pose l'hypothèse que la \"bosse\" observée dans les histogrammes représentent les vis, et les \"pics\" représent (en majorité) la valeur moyenne du bruit qu'on cherche à éliminer (soit l'arrière-plan / le convoyeur).\n",
    "\n",
    "Puisque les deux motifs observées occupent des plages de valeurs différentes, ça facilite le choix des valeurs pour les opérations de seuillage.\n",
    "\n",
    "La répartition des valeurs des canaux semble suivre (la plupart du temps) une distribution normale (*i.e.* gaussienne). On pose donc l'hypothèse que le bruit est majoritairement de nature gaussienne, et une opération de flou gaussien devrait être adéquat pour une première \"passe\" de réduction du bruit. De plus, on peut calculer la moyenne et l'écart-type de l'intensité des images, qui faciliteront davantage la valeur des paramètres de certaines opérations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramètres Intrinsèques\n",
    "\n",
    "Pour déterminer les valeurs $f_x$ et $f_y$ de la matrice $K$, on utilise les équivalences suivantes:\n",
    "\n",
    "$$ \\frac{f}{f_x} = \\frac{largeur_{capteur}}{largeur_{image}} $$\n",
    "$$ \\frac{f}{f_y} = \\frac{hauteur_{capteur}}{hauteur_{image}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic parameters and intrinsic matrix\n",
    "\n",
    "FOCAL_LENGTH = 23.0e-3  # m\n",
    "IMG_WIDTH = 640  # px\n",
    "IMG_HEIGHT = 427  # px\n",
    "SENSOR_WIDTH = 23.4e-3  # m\n",
    "SENSOR_HEIGHT = 15.6e-3  # m\n",
    "\n",
    "fx = FOCAL_LENGTH * (IMG_WIDTH / SENSOR_WIDTH)  # px\n",
    "fy = FOCAL_LENGTH * (IMG_HEIGHT / SENSOR_HEIGHT)  # px\n",
    "cx = IMG_WIDTH / 2.0  # px\n",
    "cy = IMG_HEIGHT / 2.0  # px\n",
    "skew = 0.0  # px\n",
    "\n",
    "K_tilde = np.array(\n",
    "    [\n",
    "        [fx, skew, cx, 0],\n",
    "        [0, fy, cy, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "print(f\"Matrice intrinsèque K:\\n{K_tilde}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices de transformation et de projection\n",
    "\n",
    "À partir de l'équation 2.64 du manuel de cours, on dérive l'équation pour calculer la matrice de projection en coordonnées homogènes:\n",
    "\n",
    "$$ \\tilde{P} = \\tilde{T}_{c}\\cdot\\tilde{K}^{-1}, $$\n",
    "\n",
    "où $\\tilde{T}_{c}$ est la matrice de transformation en coordonnées homogènes du repère $\\{C\\}$ au repère $\\{0\\}$.\n",
    "\n",
    "Puisque le plan $XY$ du repère $\\{0\\}$ est coplanaire avec le convoyeur, on dérive la distance verticale entre le convoyeur et la caméra:\n",
    "\n",
    "$$ z_{c} \\equiv z_{s} = \\tilde{T}_{c, \\{3, 4\\}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Homogenous extrinsic matrix (frame {C} to frame {0})\n",
    "\n",
    "w_T_c_tilde = np.array(\n",
    "    [\n",
    "        [1, 0, 0, 0.500],\n",
    "        [0, -1, 0, 0.200],\n",
    "        [0, 0, -1, 0.282],\n",
    "        [0, 0, 0, 1],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "print(f\"Matrice extrinsèque w_T_c (Camera -> World):\\n{w_T_c_tilde}\\n\")\n",
    "\n",
    "# Homogenous projection matrix\n",
    "\n",
    "w_P_c_tilde = w_T_c_tilde @ np.linalg.inv(K_tilde)  # Mathematical equivalent of P^-1\n",
    "\n",
    "print(f\"Matrice de projection complete (Camera -> World):\\n{w_P_c_tilde}\\n\")\n",
    "\n",
    "# Compute z_c\n",
    "X_0 = 0  # m\n",
    "Y_0 = 0  # m\n",
    "Z_0 = 0  # m\n",
    "z_c = (\n",
    "    w_T_c_tilde[2, 3]\n",
    "    + w_T_c_tilde[2, 0] * X_0\n",
    "    + w_T_c_tilde[2, 1] * Y_0\n",
    "    + w_T_c_tilde[2, 3] * Z_0\n",
    ")  # m\n",
    "\n",
    "print(f\"z_c: {z_c:.3f} m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procédure de résolution\n",
    "\n",
    "On cherche à identifier et caractériser les vis dans les images. On sépare le problème en deux volets:\n",
    "\n",
    "1. Isoler les vis dans l'image;\n",
    "1. Déterminer la pose des vis dans l'image.\n",
    "\n",
    "L'isolation des vis dans les images se fait par une chaîne de traitement d'image. Les paramètres de chaque étape de la chaîne sont déterminés de façon expérimentale (*i.e.* essai-erreur). La chaîne d'acquisition proposée implémente la logique suivante:\n",
    "\n",
    "1. Réduire le bruit de l'arrière-plan, de sorte à l'uniformiser;\n",
    "1. Appliquer un masque binaire à l'image afin de ségréger les vis et l'arrière-plan;\n",
    "1. Appliquer des opérations morphologiques afin d'éliminer le bruit résiduel, et assurer que la forme originale des vis soit préservée (nécessaire pour une détection de contours idéale).\n",
    "\n",
    "Pour déterminer la pose des vis dans l'image, une seconde chaîne de traitement implémente la logique suivante:\n",
    "\n",
    "1. Détecter les contours des vis;\n",
    "1. Filter les contours résultant du bruit résiduel;\n",
    "1. Trouver la boîte englobante de chaque vis afin d'extraire leurs caractéristiques de position, de dimensions, et d'orientation;\n",
    "1. Standardiser la notation des caractéristiques des vis;\n",
    "1. Classifier les vis en fonction de leurs dimensions;\n",
    "1. Convertir la position 2D dans l'image en coordonnées 3D.\n",
    "\n",
    "Additionnellement, on dessine les boîtes englobantes (accompagnées de leur identifiant respectif) sur l'image originale afin de vérifier visuellement les résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing pipeline\n",
    "\n",
    "screws: list[dict[str, int | float | str]] = []\n",
    "src_index: int = 0\n",
    "\n",
    "### VVV SPECIFY SOURCE IMAGE HERE VVV\n",
    "source = images[0]  # One-by-one processing for simplifying the problem\n",
    "### ^^^ SPECIFY SOURCE IMAGE HERE ^^^\n",
    "\n",
    "original = source.copy()\n",
    "print(f\"Image utilisée: {src_index + 1}\")\n",
    "\n",
    "float_values = np.float32(original)\n",
    "mean = np.mean(float_values)\n",
    "std_deviation = np.std(float_values)\n",
    "print(f\"Moyenne: {mean:.0f}, écart-type: {std_deviation:.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir de la moyenne et de l'écart-type calculés de l'image, et de l'analyse des histogrammes des images, on conclut qu'une valeur de `sigmaX = 2.80` pour le flou gaussien permettra de réduire efficacement le bruit de l'image sans trop affecter la clarté des vis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv.GaussianBlur(original, (7, 7), 2.80)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(blurred)\n",
    "plt.title(\"Flou gaussien\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "channels = (\"r\", \"g\", \"b\")\n",
    "plt.figure(1)\n",
    "for index, color in enumerate(channels):\n",
    "    hist = cv.calcHist([blurred], [index], None, [256], [0.0, 256.0])\n",
    "    channels = (\"r\", \"g\", \"b\")\n",
    "    plt.plot(hist, color=color)\n",
    "    plt.title(\"Histogramme - Flou gaussien\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur l'histogramme, on observe:\n",
    "\n",
    "- La \"bosse\" est toujours présente, mais sa plage de valeurs semble s'être déplacée entre `[185, 225]`;\n",
    "- Les \"pics\" sont toujours présents, mais leur plage de valeur semble aussi s'être déplacé;\n",
    "- La distinction entre la fin des \"pics\" et le début de la \"bosse\" semble être plus claire que sur l'image originale.\n",
    "\n",
    "À partir des observations de l'histogramme de l'image en aval du flou gaussien, on pose l'hypothèse qu'une valeur de seuillage de `180` permettra d'éliminer la majorité de l'arrière-plan avec un masque binaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv.cvtColor(blurred, cv.COLOR_RGB2GRAY)\n",
    "_, threshold = cv.threshold(gray, 180.0, 255.0, cv.THRESH_BINARY)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(threshold, \"gray\")\n",
    "plt.title(\"Masque binaire\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tel qu'observé dans l'image du masque binaire, les vis sont bien isolées de l'arrière-plan, et de façon générale, leur forme originale est présevée. Le bruit résiduel est presque absent, mais certaines images possèdent plus de bruit résiduel, qui pourrait résulter en des \"faux-positifs\" lors de l'extraction des caractéristiques. De plus, on observe que le contour est en \"dent de scie\" à plusieurs endroits, et \"adoucir\" le contour des vis pourrait s'avérer bénéfique en aval. Dès lors, on pose l'hypothèse que des manipulations morphologiques auront les effets suivants sur les images:\n",
    "\n",
    "- Le bruit résiduel sera presque entièrement éliminé;\n",
    "- Le contour des vis sera adouci.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv.morphologyEx(\n",
    "    threshold, cv.MORPH_OPEN, kernel=np.ones((1, 1), dtype=np.uint8)\n",
    ")  # Remove \"speckles\" (residual noise)\n",
    "dilated = cv.dilate(\n",
    "    opening, kernel=np.ones((3, 3), dtype=np.uint8), iterations=1\n",
    ")  # Smoothen the contour of screws\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(dilated, \"gray\")\n",
    "plt.title(\"Opérations morphologiques\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tel qu'observé dans l'image des opérations morphologiques, le bruit résiduel est pratiquement absent, et est considéré négligeable: un filtre basé sur la superficie d'un \"blob\" éliminera la possibilité d'un \"faux-positif\" dans l'extraction des caractéristiques. Malheureusement, le contour des vis n'est pas vraiment \"adouci\". Toutefois, l'épaisseur des vis semble avoir augmenté. On pose l'hypothèse que l'effet observé permettra de distinguer davantage les vis du bruit résiduel, alors la manipulation est retenue.\n",
    "\n",
    "Les contours détectés des images sont filtrer en fonction de leur superficie. Les bornes inférieures et supérieures du filtre ont été déterminé à partir des hypothèses suivantes:\n",
    "\n",
    "- La superficie d'une agglomération représentant du bruit résiduel ne dépasse pas 100 pixels;\n",
    "- La superficie totale d'une vis, en considérant sa dilatation après transformation morphologiqe, sera inférieure à 2 % de la superficie totale de l'image, soit environ 5000 pixels.\n",
    "\n",
    "En ce qui concerne la classification des vis, on utilise la hauteur de la boîte englobante du contour détecté comme paramètre. La valeur du seuil de distinction entre une vis courte et une vis longue a été déterminée expérimentalement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caracteristics extraction\n",
    "\n",
    "contours, _ = cv.findContours(dilated, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "MIN_SCREW_AREA = 100  # px\n",
    "MAX_SCREW_AREA = 5000  # px\n",
    "HEIGHT_THRESHOLD = 100  # px\n",
    "\n",
    "results = []\n",
    "screw_id: int = 0\n",
    "\n",
    "for contour in contours:\n",
    "    area = cv.contourArea(contour)\n",
    "    if area < MIN_SCREW_AREA or area > MAX_SCREW_AREA:\n",
    "        continue\n",
    "\n",
    "    rect = cv.minAreaRect(contour)\n",
    "    (c_u, c_v), (width, height), theta = rect\n",
    "\n",
    "    # Draw bounding box and id\n",
    "    bbox = cv.boxPoints(rect)\n",
    "    bbox = np.intp(bbox)  # Convert box points to integer type for drawing\n",
    "    cv.drawContours(original, [bbox], 0, (0, 0, 255), 2)  # type: ignore\n",
    "    cv.putText(\n",
    "        original,\n",
    "        str(screw_id),\n",
    "        (int(c_u) - 5, int(c_v) - 5),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        1.0,\n",
    "        (255, 0, 0),\n",
    "        3,\n",
    "        cv.LINE_AA,\n",
    "    )\n",
    "\n",
    "    # Standardise bounding box notation\n",
    "    if width > height:\n",
    "        width, height = height, width\n",
    "        theta += 90\n",
    "    theta = (theta + 90) % 180\n",
    "    theta = (360 - theta) % 180\n",
    "\n",
    "    screw_type = \"courte\"\n",
    "    if height > HEIGHT_THRESHOLD:\n",
    "        screw_type = \"longue\"\n",
    "\n",
    "    # Screen space to camera space\n",
    "    z_screen = z_c  # px?\n",
    "    x_screen = c_u * z_screen  # px^2?\n",
    "    y_screen = c_v * z_screen  # px^2?\n",
    "    X_s_prime = np.array([x_screen, y_screen, z_screen, 1], dtype=np.float32)\n",
    "\n",
    "    # Camera space to world space\n",
    "    p_w = w_P_c_tilde @ X_s_prime\n",
    "    x_0, y_0, z_0, _ = p_w\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"id\": screw_id,\n",
    "            \"type\": screw_type,\n",
    "            \"X\": x_0,\n",
    "            \"Y\": y_0,\n",
    "            \"Z\": z_0,\n",
    "            \"theta\": theta,\n",
    "        }\n",
    "    )\n",
    "    screw_id += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note sur le calcul de l'orientation\n",
    "\n",
    "Le calcul de l'orientation des vis est effectué à partir de la boîte englobante. Toutefois, tel qu'observé dans les images annotées, l'orientation des boîtes diffère un peu de l'orientation des vis: il y a donc une certaine tolérance associée aux valeurs de l'orientation (de l'ordre de quelques degrés).\n",
    "\n",
    "Une stratégie qui résulterait en des valeurs plus justes serait d'utiliser la transformée de Hough pour identifier les lignes \"directrices\" dans l'image, qui sont parallèles aux vis. Cette stratégie possède aussi des limites: plusieurs lignes peuvent appartenir à la même vis. Les résultats de la transformée nécessite donc d'être agglomérer (*clustering*).\n",
    "\n",
    "Expérimentalement, des paramètres de l'algorithme d'agglomération qui permettent d'obtenir un ratio $1:1$ (c.à.d. une ligne par vis) n'ont pas été identifiés. Considérant que l'agglomération des lignes est en dehors de la portée du cours, les résultats produits par l'algorithme d'agglomération ne sont pas utilisés. Dès lors, cette stratégie n'est pas implémentée dans ce code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "\n",
    "print(f\"Image {src_index + 1}:\\n\")\n",
    "print(\n",
    "    tabulate.tabulate(\n",
    "        [\n",
    "            [\n",
    "                screw[\"id\"],\n",
    "                screw[\"type\"],\n",
    "                screw[\"X\"],\n",
    "                screw[\"Y\"],\n",
    "                screw[\"Z\"],\n",
    "                screw[\"theta\"],\n",
    "            ]\n",
    "            for screw in results\n",
    "        ],\n",
    "        headers=[\n",
    "            \"id\",\n",
    "            \"Type\",\n",
    "            \"X (m)\",\n",
    "            \"Y (m)\",\n",
    "            \"Z (m)\",\n",
    "            \"theta (deg)\",\n",
    "        ],\n",
    "        floatfmt=\".3f\",\n",
    "    )\n",
    ")\n",
    "print()\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(original)\n",
    "plt.title(f\"Image {src_index + 1} - Résultats du traitement\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des résultats\n",
    "\n",
    "On observe que la chaîne de traitement d'images produit des résultats qui sont, de façon générale, adéquats pour répondre au problème posé. Toutefois, la faiblesse principale notée de la chaîne de traitement est l'utilisation de la boîte englobante pour déterminer l'orientation des vis. Effectivement, tel qu'observé sur l'image annotée, la boîte englobante n'est pas parfaitement alignée avec la vis, ce qui résulte en une erreur sur l'orientation. Expérimentalement, la borne supérieure de cette erreur a été évaluée à un ordre de $\\pm 10\\degree$, ce qui n'est pas négligeable. Pour mitiger cette erreur, on suggère d'augmenter l'ouverture du préhenseur, de sorte que la plage de valeurs de l'orientation d'une vis soit entièrement couverte.\n",
    "\n",
    "L'autre faiblesse identifiée de la chaîne de traitement d'images est le manque de diversité dans les échantillons utilisés pour convevoir la chaîne: on pourrait considérer cette faiblesse comme l'analogue du sur-entraînement d'un modèle d'intelligence articifielle. Certes, la performance de la chaîne sur les échantillons fournis est adéquate, mais une image où des débris s'entremêlent avec les vis pourrait résulter en une performance médiocre. Autrement dit, la chaîne de traitement n'est pas considérée robuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifications pour le traitement par lots\n",
    "\n",
    "Tel qu'illustré dans les résultats affichés plus bas, la moyenne et l'écart-type est différente pour chaque image, et l'utilisation d'une valeur de `sigmaX = 2.80` pour le flou gaussien n'est pas appropriée pour les images avec un écart-type plus élevé. Dès lors, on conclut qu'une stratégie plus efficace est de déterminer dynamiquement la valeur de `sigmaX` en fonction des paramètres de la distribution normale de l'image originale. L'équation utilisée est:\n",
    "\n",
    "$$\\sigma_{x} = \\frac{210 - \\mu}{\\sigma},$$\n",
    "\n",
    "où $\\mu$ et $\\sigma$ sont la moyenne et l'écart-type calculés de l'image originale. La valeur $210$ provient de l'analyse des histogrammes des images originales, où la plage des valeurs des \"bosses\" se situe entre $[210, 240]$. On pose l'hypothèse qu'en utilisant la borne inférieure de la plage de valeurs, on réduit considérablement l'effet du flou gaussien sur les vis tout en maximisant l'effet sur le bruit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing pipeline\n",
    "\n",
    "normal_distribution_params: list[tuple[int, int, float]] = []\n",
    "blurred_histrograms: list[list[cv.typing.MatLike]] = []\n",
    "processed_images: list[cv.typing.MatLike] = []\n",
    "all_results: list[list[dict[str, int | float | str]]] = []\n",
    "\n",
    "for index, image in enumerate(images):\n",
    "    original = image.copy()\n",
    "\n",
    "    # Compute normal distribution parameters\n",
    "    float_values = np.float32(original)\n",
    "    mean = np.mean(float_values)\n",
    "    std_deviation = np.std(float_values)\n",
    "    target_sigma = float((210.0 - mean) / std_deviation)\n",
    "    normal_distribution_params.append((int(mean), int(std_deviation), target_sigma))\n",
    "\n",
    "    # Image transformations\n",
    "\n",
    "    blurred = cv.GaussianBlur(original, (7, 7), target_sigma)\n",
    "    histograms: list[cv.typing.MatLike] = []\n",
    "    channels = (\"r\", \"g\", \"b\")\n",
    "    for jj, _ in enumerate(channels):\n",
    "        hist = cv.calcHist([blurred], [jj], None, [256], [0, 256])\n",
    "        histograms.append(hist)\n",
    "    blurred_histrograms.append(histograms)\n",
    "\n",
    "    gray = cv.cvtColor(blurred, cv.COLOR_RGB2GRAY)\n",
    "    _, threshold = cv.threshold(gray, 180.0, 255.0, cv.THRESH_BINARY)\n",
    "\n",
    "    opening = cv.morphologyEx(\n",
    "        threshold, cv.MORPH_OPEN, kernel=np.ones((1, 1), dtype=np.uint8)\n",
    "    )\n",
    "    dilated = cv.dilate(opening, kernel=np.ones((3, 3), dtype=np.uint8), iterations=1)\n",
    "    processed_images.append(dilated)\n",
    "\n",
    "    # Caracteristics extraction\n",
    "\n",
    "    contours, _ = cv.findContours(dilated, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    MIN_SCREW_AREA = 100  # px\n",
    "    MAX_SCREW_AREA = 5000  # px\n",
    "    HEIGHT_THRESHOLD = 100  # px\n",
    "\n",
    "    results: list[dict[str, int | float | str]] = []\n",
    "    screw_id: int = 0\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv.contourArea(contour)\n",
    "        if area < MIN_SCREW_AREA or area > MAX_SCREW_AREA:\n",
    "            continue\n",
    "\n",
    "        rect = cv.minAreaRect(contour)\n",
    "        (c_u, c_v), (width, height), theta = rect\n",
    "\n",
    "        # Draw bounding box and id\n",
    "        bbox = cv.boxPoints(rect)\n",
    "        bbox = np.intp(bbox)  # Convert box points to integer type for drawing\n",
    "        cv.drawContours(image, [bbox], 0, (0, 0, 255), 2)  # type: ignore\n",
    "        cv.putText(\n",
    "            image,\n",
    "            str(screw_id),\n",
    "            (int(c_u) - 5, int(c_v) - 5),\n",
    "            cv.FONT_HERSHEY_SIMPLEX,\n",
    "            1.0,\n",
    "            (255, 0, 0),\n",
    "            3,\n",
    "            cv.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Standardise bounding box notation\n",
    "        if width > height:\n",
    "            width, height = height, width\n",
    "            theta += 90\n",
    "        theta = theta + 90  # ∈ [0, 180[, CW positive\n",
    "        theta = (360 - theta) % 180  # Convert to CCW positive\n",
    "\n",
    "        screw_type = \"courte\"\n",
    "        if height > HEIGHT_THRESHOLD:\n",
    "            screw_type = \"longue\"\n",
    "\n",
    "        # Screen space to camera space\n",
    "        z_screen = z_c  # px?\n",
    "        x_screen = c_u * z_screen  # px^2?\n",
    "        y_screen = c_v * z_screen  # px^2?\n",
    "        X_s_prime = np.array([x_screen, y_screen, z_screen, 1], dtype=np.float32)\n",
    "\n",
    "        # Camera space to world space\n",
    "        p_w = w_P_c_tilde @ X_s_prime\n",
    "        x_0, y_0, z_0, _ = p_w\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"id\": screw_id,\n",
    "                \"type\": screw_type,\n",
    "                \"X\": x_0,\n",
    "                \"Y\": y_0,\n",
    "                \"Z\": z_0,\n",
    "                \"theta\": theta,\n",
    "            }\n",
    "        )\n",
    "        screw_id += 1\n",
    "\n",
    "    all_results.append(results)\n",
    "\n",
    "\n",
    "# Display intermediary results\n",
    "\n",
    "title = \"Paramètres de distribution normale des images originales\"\n",
    "print(f\"{title}\\n{'=' * len(title)}\")\n",
    "print(\n",
    "    tabulate.tabulate(\n",
    "        [\n",
    "            [index + 1, params[0], params[1], params[2]]\n",
    "            for index, params in enumerate(normal_distribution_params)\n",
    "        ],\n",
    "        headers=[\"Image\", \"moyenne\", \"écart-type\", \"'sigmaX' visé\"],\n",
    "        floatfmt=\".3f\",\n",
    "    )\n",
    ")\n",
    "print()\n",
    "\n",
    "plt.figure(0)\n",
    "plt.suptitle(\"Histogrammes - Flou gaussien\")\n",
    "for index, histogram in enumerate(blurred_histrograms):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    channels = (\"r\", \"g\", \"b\")\n",
    "    for i, col in enumerate(channels):\n",
    "        plt.plot(histogram[i], color=col)\n",
    "        plt.gca().set_ylim(bottom=0)\n",
    "        plt.tight_layout()\n",
    "    plt.title(f\"Image {index + 1}\")\n",
    "plt.show()\n",
    "\n",
    "# Display results\n",
    "\n",
    "title = \"Tableau des résultats\"\n",
    "print(f\"{title}\\n{'=' * len(title)}\")\n",
    "for index, _ in enumerate(images):\n",
    "    print(f\"Image {index + 1}:\\n\")\n",
    "    print(\n",
    "        tabulate.tabulate(\n",
    "            [\n",
    "                [\n",
    "                    screw[\"id\"],\n",
    "                    screw[\"type\"],\n",
    "                    screw[\"X\"],\n",
    "                    screw[\"Y\"],\n",
    "                    screw[\"Z\"],\n",
    "                    screw[\"theta\"],\n",
    "                ]\n",
    "                for screw in all_results[index]\n",
    "            ],\n",
    "            headers=[\n",
    "                \"id\",\n",
    "                \"Type\",\n",
    "                \"X (m)\",\n",
    "                \"Y (m)\",\n",
    "                \"Z (m)\",\n",
    "                \"theta (deg)\",\n",
    "            ],\n",
    "            floatfmt=\".3f\",\n",
    "        )\n",
    "    )\n",
    "    print()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.suptitle(\"Images traitées\")\n",
    "for index, image in enumerate(processed_images):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    plt.imshow(image, \"gray\")\n",
    "    plt.title(f\"Image {index + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.suptitle(\"Images annotées\")\n",
    "for index, image in enumerate(images):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Image {index + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline alternatif\n",
    "\n",
    "Un pipeline alternatif plus simple a été testé. La chaîne consistait en un filtre bilatéral avec la signature `bilateralFilter(original, d=9, sigmaColor=75.0, sigmaSapce=75.0)`, suivie de l'opération de seuillage utilisée dans la chaîne implémentée ci-dessus (même paramètres). Les observations suivantes ont été réalisées:\n",
    "\n",
    "- Le bruit résiduel est moindre;\n",
    "- La boîte englobante est généralement mieux centrée sur les vis, et l'orientation est ainsi plus précise;\n",
    "- La tête des vis, plus particulièrement les vis courtes, est parfois filtrée de l'image, et la boîte englobante ne couvre pas ces têtes.\n",
    "\n",
    "> *N.B.* Les valeurs des paramètres du filtre bilatéral ont été déterminés expérimentalement (en termes grossiers: \"au *feeling*\"), et ne possèdent pas de justification \"logique\".\n",
    "\n",
    "Les deux chaînes évaluées offrent un compromis différent. Les performances des deux chaînes sont jugées adéquates (et similaires) pour répondre au besoin du problème posé. Certes, le pipeline alternatif est plus simple et plus élégant, mais on pose l'hypothèse qu'en raison de sa simplicité, il est moins robuste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative processing pipeline\n",
    "\n",
    "# Reload images (to avoid annotating over the images from the previous pipeline)\n",
    "\n",
    "image_filenames = os.listdir(\"photos_prob/\")\n",
    "image_filenames.sort()\n",
    "assert image_filenames is not None\n",
    "print(f\"{len(image_filenames)} images à traiter:\")\n",
    "\n",
    "images: list[cv.typing.MatLike] = []\n",
    "\n",
    "for filename in image_filenames:\n",
    "    path = os.path.join(\"photos_prob/\", filename)\n",
    "    img = cv.imread(path)\n",
    "    assert img is not None\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "\n",
    "normal_distribution_params: list[tuple[int, int, float]] = []\n",
    "blurred_histrograms: list[list[cv.typing.MatLike]] = []\n",
    "processed_images: list[cv.typing.MatLike] = []\n",
    "all_results: list[list[dict[str, int | float | str]]] = []\n",
    "\n",
    "for index, image in enumerate(images):\n",
    "    original = image.copy()\n",
    "\n",
    "    # Image transformations\n",
    "    \n",
    "    blurred = cv.bilateralFilter(original, 9, 75.0, 75.0)\n",
    "    histograms: list[cv.typing.MatLike] = []\n",
    "    channels = (\"r\", \"g\", \"b\")\n",
    "    for jj, _ in enumerate(channels):\n",
    "        hist = cv.calcHist([blurred], [jj], None, [256], [0, 256])\n",
    "        histograms.append(hist)\n",
    "    blurred_histrograms.append(histograms)\n",
    "\n",
    "    gray = cv.cvtColor(blurred, cv.COLOR_RGB2GRAY)\n",
    "    _, threshold = cv.threshold(gray, 195.0, 255.0, cv.THRESH_BINARY)\n",
    "    processed_images.append(threshold)\n",
    "\n",
    "    # Caracteristics extraction\n",
    "\n",
    "    contours, _ = cv.findContours(threshold, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    MIN_SCREW_AREA = 100  # px\n",
    "    MAX_SCREW_AREA = 5000  # px\n",
    "    HEIGHT_THRESHOLD = 100  # px\n",
    "\n",
    "    results: list[dict[str, int | float | str]] = []\n",
    "    screw_id: int = 0\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv.contourArea(contour)\n",
    "        if area < MIN_SCREW_AREA or area > MAX_SCREW_AREA:\n",
    "            continue\n",
    "\n",
    "        rect = cv.minAreaRect(contour)\n",
    "        (c_u, c_v), (width, height), theta = rect\n",
    "\n",
    "        # Draw bounding box and id\n",
    "        bbox = cv.boxPoints(rect)\n",
    "        bbox = np.intp(bbox)  # Convert box points to integer type for drawing\n",
    "        cv.drawContours(image, [bbox], 0, (0, 0, 255), 2)  # type: ignore\n",
    "        cv.putText(\n",
    "            image,\n",
    "            str(screw_id),\n",
    "            (int(c_u) - 5, int(c_v) - 5),\n",
    "            cv.FONT_HERSHEY_SIMPLEX,\n",
    "            1.0,\n",
    "            (255, 0, 0),\n",
    "            3,\n",
    "            cv.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Standardise bounding box notation\n",
    "        if width > height:\n",
    "            width, height = height, width\n",
    "            theta += 90\n",
    "        theta = theta + 90  # ∈ [0, 180[, CW positive\n",
    "        theta = (360 - theta) % 180  # Convert to CCW positive\n",
    "\n",
    "        screw_type = \"courte\"\n",
    "        if height > HEIGHT_THRESHOLD:\n",
    "            screw_type = \"longue\"\n",
    "\n",
    "        # Screen space to camera space\n",
    "        z_screen = z_c  # px?\n",
    "        x_screen = c_u * z_screen  # px^2?\n",
    "        y_screen = c_v * z_screen  # px^2?\n",
    "        X_s_prime = np.array([x_screen, y_screen, z_screen, 1], dtype=np.float32)\n",
    "\n",
    "        # Camera space to world space\n",
    "        p_w = w_P_c_tilde @ X_s_prime\n",
    "        x_0, y_0, z_0, _ = p_w\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"id\": screw_id,\n",
    "                \"type\": screw_type,\n",
    "                \"X\": x_0,\n",
    "                \"Y\": y_0,\n",
    "                \"Z\": z_0,\n",
    "                \"theta\": theta,\n",
    "            }\n",
    "        )\n",
    "        screw_id += 1\n",
    "\n",
    "    all_results.append(results)\n",
    "\n",
    "\n",
    "# Display intermediary results\n",
    "\n",
    "title = \"Paramètres de distribution normale des images originales\"\n",
    "print(f\"{title}\\n{'=' * len(title)}\")\n",
    "print(\n",
    "    tabulate.tabulate(\n",
    "        [\n",
    "            [index + 1, params[0], params[1], params[2]]\n",
    "            for index, params in enumerate(normal_distribution_params)\n",
    "        ],\n",
    "        headers=[\"Image\", \"moyenne\", \"écart-type\", \"'sigmaX' visé\"],\n",
    "        floatfmt=\".3f\",\n",
    "    )\n",
    ")\n",
    "print()\n",
    "\n",
    "plt.figure(0)\n",
    "plt.suptitle(\"Histogrammes - Flou bilatéral\")\n",
    "for index, histogram in enumerate(blurred_histrograms):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    channels = (\"r\", \"g\", \"b\")\n",
    "    for i, col in enumerate(channels):\n",
    "        plt.plot(histogram[i], color=col)\n",
    "        plt.gca().set_ylim(bottom=0)\n",
    "        plt.tight_layout()\n",
    "    plt.title(f\"Image {index + 1}\")\n",
    "plt.show()\n",
    "\n",
    "# Display results\n",
    "\n",
    "title = \"Tableau des résultats\"\n",
    "print(f\"{title}\\n{'=' * len(title)}\")\n",
    "for index, _ in enumerate(images):\n",
    "    print(f\"Image {index + 1}:\\n\")\n",
    "    print(\n",
    "        tabulate.tabulate(\n",
    "            [\n",
    "                [\n",
    "                    screw[\"id\"],\n",
    "                    screw[\"type\"],\n",
    "                    screw[\"X\"],\n",
    "                    screw[\"Y\"],\n",
    "                    screw[\"Z\"],\n",
    "                    screw[\"theta\"],\n",
    "                ]\n",
    "                for screw in all_results[index]\n",
    "            ],\n",
    "            headers=[\n",
    "                \"id\",\n",
    "                \"Type\",\n",
    "                \"X (m)\",\n",
    "                \"Y (m)\",\n",
    "                \"Z (m)\",\n",
    "                \"theta (deg)\",\n",
    "            ],\n",
    "            floatfmt=\".3f\",\n",
    "        )\n",
    "    )\n",
    "    print()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.suptitle(\"Images traitées\")\n",
    "for index, image in enumerate(processed_images):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    plt.imshow(image, \"gray\")\n",
    "    plt.title(f\"Image {index + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.suptitle(\"Images annotées\")\n",
    "for index, image in enumerate(images):\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Image {index + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prob.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
